import os
import speech_recognition as sr
from pydub import AudioSegment
from pydub.silence import split_on_silence
from transformers import pipeline
import yt_dlp
from yt_dlp import YoutubeDL

# Input YouTube URL
youtube_URL = input("Enter the URL of the video: ")

# Options for extracting video info
ydl_opts = {
    'quiet': True,  # Suppress output
    'no_warnings': True,  # Suppress warnings
}

# Extract video info
with YoutubeDL(ydl_opts) as ydl:
    info_dict = ydl.extract_info(youtube_URL, download=False)
    print("Title: ", info_dict.get('title', 'No title available'))
    print("Number of views: ", info_dict.get('view_count', 'No view count available'))
    print("Length of video: ", info_dict.get('duration', 'No duration available'), "seconds")
    print("Description: ", info_dict.get('description', 'No description available'))
    print("Author: ", info_dict.get('uploader', 'No author available'))

    # Download audio
    print("Downloading audio...")
    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': 'audio.%(ext)s',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192',
        }],
    }
    with YoutubeDL(ydl_opts) as ydl:
        ydl.download([youtube_URL])

# Speech-to-Text
r = sr.Recognizer()

def transcribe_audio(path):
    """Transcribe audio file to text using Google Speech Recognition."""
    with sr.AudioFile(path) as source:
        audio_listened = r.record(source)
        text = r.recognize_google(audio_listened)
    return text

def get_large_audio_transcription_on_silence(path):
    """Split the audio file into chunks and apply speech recognition on each chunk."""
    sound = AudioSegment.from_file(path)
    chunks = split_on_silence(
        sound,
        min_silence_len=500,  # Minimum silence length to split on (in milliseconds)
        silence_thresh=sound.dBFS - 14,  # Silence threshold (in dB)
        keep_silence=500,  # Keep some silence at the beginning and end of chunks (in milliseconds)
    )
    folder_name = "audio-chunks"
    if not os.path.isdir(folder_name):
        os.mkdir(folder_name)
    whole_text = ""
    for i, audio_chunk in enumerate(chunks, start=1):
        chunk_filename = os.path.join(folder_name, f"chunk{i}.wav")  # Use WAV for better compatibility
        audio_chunk.export(chunk_filename, format="wav")
        try:
            text = transcribe_audio(chunk_filename)
        except sr.UnknownValueError as e:
            print("Error:", str(e))
        else:
            text = f"{text.capitalize()}. "
            print(chunk_filename, ":", text)
            whole_text += text
    return whole_text

# Transcribe the downloaded audio file
audio_file = "audio.mp3"
print("\nFull text:", get_large_audio_transcription_on_silence(audio_file))

# Save transcribed text to a file
with open("notes.txt", "w", encoding="utf-8") as file1:
    file1.write(get_large_audio_transcription_on_silence(audio_file))

# Summarization
def summarize_long_text(text, max_input_length=1024, max_summary_length=150):
    """Summarize long text using the Hugging Face BART model."""
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
    # Split text into chunks of max_input_length
    chunks = [text[i:i + max_input_length] for i in range(0, len(text), max_input_length)]
    summaries = []
    for chunk in chunks:
        if chunk.strip():  # Ensure the chunk is not empty
            try:
                summary = summarizer(chunk, max_length=max_summary_length, min_length=30, do_sample=False)
                summaries.append(summary[0]['summary_text'])
            except Exception as e:
                print(f"Error summarizing chunk: {e}")
    return summaries

# Read the transcribed text
with open("notes.txt", "r", encoding="utf-8") as file:
    text = file.read()

# Check if the text is not empty
if not text.strip():
    print("Error: The transcribed text is empty. Cannot summarize.")
else:
    # Summarize the text
    final_summary = summarize_long_text(text)

    if final_summary:
        # Format the summary for readability
        formatted_summary = "\n".join(final_summary)  # Join summaries with newlines
        print("Summary:\n", formatted_summary)

        # Save the summary to a file
        with open("summary.txt", "w", encoding="utf-8") as output_file:
            output_file.write(formatted_summary)
    else:
        print("Error: No summary generated. Check the input text or summarization model.")
